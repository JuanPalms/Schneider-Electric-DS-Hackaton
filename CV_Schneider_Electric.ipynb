{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBEZbaMe3hSy"
   },
   "source": [
    "# Schneider Electric  Data Science challenge\n",
    "\n",
    "\n",
    "\n",
    "## PART I : CNN with transfer learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUQDqAAC3RjA",
    "outputId": "cb4b9e7b-0a2a-47c0-80fa-4a5aa8884156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IeNcBlnO6Gxv"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "B3Zcrkf56IRh"
   },
   "outputs": [],
   "source": [
    "ruta=os.getcwd()+'/drive/MyDrive/Schneider competition/train_test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0vLQjJoA5M06"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elhddpBO56qD"
   },
   "source": [
    "Defining training, validation and test directories roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "D8-j95GN6DoR"
   },
   "outputs": [],
   "source": [
    "train_data_dir=ruta+\"/training\"\n",
    "validation_data_dir=ruta+\"/validation\"\n",
    "test_data_dir=ruta+\"/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v825biX64v-Y"
   },
   "source": [
    "### Data Agumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8tmEaxQ7ZG6"
   },
   "source": [
    "Defining Initial parameters for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orKzC8Nz4y_O",
    "outputId": "32c8510a-ce35-4282-a9ef-26dba3842ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1857 images belonging to 3 classes.\n",
      "Found 445 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "inception_v3_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.10, \n",
    "    brightness_range=[0.6,1.4],\n",
    "    channel_shift_range=0.7,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "train_generator_inception_v3 = inception_v3_datagen.flow_from_directory(\n",
    "        train_data_dir,  \n",
    "        target_size=(300, 300),  \n",
    "        batch_size=16,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False,\n",
    ")\n",
    "\n",
    "\n",
    "val_generator_inception_v3 = inception_v3_datagen.flow_from_directory(\n",
    "        validation_data_dir,  \n",
    "        target_size=(300, 300),  \n",
    "        batch_size=16,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vqf4-bOf7vyg"
   },
   "source": [
    "### Inception architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zIfx-blF97Ye"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, GlobalAveragePooling2D, UpSampling2D, Input, LeakyReLU\n",
    "from keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62KyIlfd7mTK",
    "outputId": "08d98a02-a020-4010-81c4-9be845efda0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 4s 0us/step\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 300, 300, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          1049088     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          262656      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 3)            1539        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,116,067\n",
      "Trainable params: 1,708,163\n",
      "Non-trainable params: 21,407,904\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "InceptionV3_model = tensorflow.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "for layer in InceptionV3_model.layers[:-15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = InceptionV3_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "# Define last layer fully conected and set 3 categories\n",
    "output  = Dense(units=3, activation='softmax')(x)\n",
    "model_inception = Model(InceptionV3_model.input, output)\n",
    "\n",
    "model_inception.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nahf-Q-q-Cru",
    "outputId": "02ffa00b-56f0-4268-8554-ee4b6d32ab24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 997s 8s/step - loss: 1.1652 - accuracy: 0.3393 - val_loss: 0.5912 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 54s 463ms/step - loss: 1.0766 - accuracy: 0.4163 - val_loss: 0.6128 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 55s 467ms/step - loss: 1.0346 - accuracy: 0.4685 - val_loss: 1.1215 - val_accuracy: 0.2125\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 55s 468ms/step - loss: 1.0154 - accuracy: 0.4755 - val_loss: 0.7516 - val_accuracy: 0.8562\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 54s 458ms/step - loss: 0.9331 - accuracy: 0.5514 - val_loss: 0.5792 - val_accuracy: 0.8875\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 54s 460ms/step - loss: 0.8263 - accuracy: 0.6252 - val_loss: 1.1584 - val_accuracy: 0.3938\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 55s 471ms/step - loss: 0.7697 - accuracy: 0.6333 - val_loss: 0.8791 - val_accuracy: 0.6062\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 54s 465ms/step - loss: 0.6847 - accuracy: 0.6882 - val_loss: 0.2310 - val_accuracy: 0.9750\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 54s 462ms/step - loss: 0.6077 - accuracy: 0.7297 - val_loss: 0.4512 - val_accuracy: 0.8687\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 54s 464ms/step - loss: 0.5383 - accuracy: 0.7631 - val_loss: 1.2990 - val_accuracy: 0.3812\n"
     ]
    }
   ],
   "source": [
    "optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model_inception.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"])\n",
    "history_inception = model_inception.fit(train_generator_inception_v3,  epochs=10, validation_data=val_generator_inception_v3, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHbkuxKnPLfd",
    "outputId": "1afe73fa-63f2-4128-b79b-a1f25a3700c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "predictions=model_inception.predict_generator(generator=val_generator_inception_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pznz4G2uPcP1"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmrkcLtMPWjG"
   },
   "outputs": [],
   "source": [
    "y_pred=np.argmax(predictions, axis=1)\n",
    "y_real= val_generator_inception_v3.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "E0KGpU0gPep-",
    "outputId": "0b323173-af68-47ca-cd38-187e02d94c00"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(y_real, y_pred, normalize='true');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wtwn6jqMPj3J",
    "outputId": "b79193ce-67b9-4b24-9580-7f7dc05044ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7455    0.4249    0.5413       193\n",
      "           1     0.5956    0.5956    0.5956       136\n",
      "           2     0.4020    0.6897    0.5079       116\n",
      "\n",
      "    accuracy                         0.5461       445\n",
      "   macro avg     0.5810    0.5700    0.5483       445\n",
      "weighted avg     0.6101    0.5461    0.5492       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_real,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlyyLsXjQYE-"
   },
   "source": [
    "I get a poor performance, i'll try with other architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJrzMJ5OQaZJ",
    "outputId": "edb010c7-6779-4787-9f04-41d785f30819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1857 images belonging to 3 classes.\n",
      "Found 445 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "EfficientNetB3_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.10,\n",
    "    brightness_range=[0.6,1.4],\n",
    "    channel_shift_range=0.7,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input\n",
    ") \n",
    "train_generator_EfficientNetB3 = EfficientNetB3_datagen.flow_from_directory(\n",
    "        train_data_dir,  \n",
    "        target_size=(300, 300), \n",
    "        batch_size=20,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "val_generator_EfficientNetB3 = EfficientNetB3_datagen.flow_from_directory(\n",
    "        validation_data_dir,  \n",
    "        target_size=(300, 300), \n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WN0_2kG8UvWx"
   },
   "outputs": [],
   "source": [
    "img_shape=(300, 300, 3)\n",
    "model_name='EfficientNetB3'\n",
    "EfficientNetB3_model=tensorflow.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n",
    "for layer in EfficientNetB3_model.layers[:-15]:\n",
    "    layer.trainable = False\n",
    "x = EfficientNetB3_model.output\n",
    "x = BatchNormalization(axis=-1, epsilon=0.001)(x)\n",
    "x = Dense(256,activation='relu')(x)\n",
    "x = Dropout(rate=.3)(x)       \n",
    "output=Dense(3, activation='softmax')(x)\n",
    "EfficientNetB3_model = Model(inputs=EfficientNetB3_model.input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TwMd4bjVKeJ",
    "outputId": "213ecd3f-e07a-4498-af24-8adde5d65669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "93/93 [==============================] - 81s 765ms/step - loss: 1.1552 - accuracy: 0.5412 - val_loss: 0.9027 - val_accuracy: 0.6427\n",
      "Epoch 2/15\n",
      "93/93 [==============================] - 68s 737ms/step - loss: 0.9492 - accuracy: 0.6042 - val_loss: 0.8732 - val_accuracy: 0.6090\n",
      "Epoch 3/15\n",
      "93/93 [==============================] - 69s 740ms/step - loss: 0.8802 - accuracy: 0.6327 - val_loss: 0.8835 - val_accuracy: 0.6337\n",
      "Epoch 4/15\n",
      "93/93 [==============================] - 69s 738ms/step - loss: 0.8440 - accuracy: 0.6484 - val_loss: 0.7501 - val_accuracy: 0.6787\n",
      "Epoch 5/15\n",
      "93/93 [==============================] - 69s 738ms/step - loss: 0.7647 - accuracy: 0.6812 - val_loss: 0.7448 - val_accuracy: 0.7101\n",
      "Epoch 6/15\n",
      "93/93 [==============================] - 69s 739ms/step - loss: 0.7530 - accuracy: 0.6909 - val_loss: 0.8160 - val_accuracy: 0.6652\n",
      "Epoch 7/15\n",
      "93/93 [==============================] - 69s 739ms/step - loss: 0.6936 - accuracy: 0.7151 - val_loss: 0.8090 - val_accuracy: 0.6562\n",
      "Epoch 8/15\n",
      "93/93 [==============================] - 69s 741ms/step - loss: 0.7012 - accuracy: 0.7119 - val_loss: 0.7144 - val_accuracy: 0.6876\n",
      "Epoch 9/15\n",
      "93/93 [==============================] - 69s 740ms/step - loss: 0.6516 - accuracy: 0.7318 - val_loss: 0.7419 - val_accuracy: 0.7034\n",
      "Epoch 10/15\n",
      "93/93 [==============================] - 69s 739ms/step - loss: 0.6568 - accuracy: 0.7270 - val_loss: 0.7856 - val_accuracy: 0.6989\n",
      "Epoch 11/15\n",
      "93/93 [==============================] - 69s 741ms/step - loss: 0.6071 - accuracy: 0.7561 - val_loss: 0.7460 - val_accuracy: 0.7079\n",
      "Epoch 12/15\n",
      "93/93 [==============================] - 69s 740ms/step - loss: 0.5882 - accuracy: 0.7614 - val_loss: 0.7298 - val_accuracy: 0.7258\n",
      "Epoch 13/15\n",
      "93/93 [==============================] - 69s 741ms/step - loss: 0.5875 - accuracy: 0.7539 - val_loss: 0.7135 - val_accuracy: 0.7281\n",
      "Epoch 14/15\n",
      "93/93 [==============================] - 69s 745ms/step - loss: 0.5490 - accuracy: 0.7668 - val_loss: 0.7518 - val_accuracy: 0.7101\n",
      "Epoch 15/15\n",
      "93/93 [==============================] - 69s 738ms/step - loss: 0.5434 - accuracy: 0.7787 - val_loss: 0.7284 - val_accuracy: 0.7213\n"
     ]
    }
   ],
   "source": [
    "optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "EfficientNetB3_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "history_eff = EfficientNetB3_model.fit(train_generator_EfficientNetB3, epochs=15, validation_data=val_generator_EfficientNetB3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-rDLyJOX1GA",
    "outputId": "9c5390ba-94b0-402b-c0df-8183f13996db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "predictions_efficient=EfficientNetB3_model.predict_generator(generator=val_generator_EfficientNetB3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VEwL5eihuOe",
    "outputId": "8ecabdbe-21ef-4c7d-d312-7c363aa52544"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9994314e-01, 1.5644542e-07, 5.6743982e-05],\n",
       "       [9.9084657e-01, 7.0926052e-04, 8.4441146e-03],\n",
       "       [8.7834853e-01, 1.2954999e-03, 1.2035594e-01],\n",
       "       ...,\n",
       "       [8.4197909e-02, 2.9147379e-02, 8.8665468e-01],\n",
       "       [1.0347750e-02, 1.7957047e-02, 9.7169524e-01],\n",
       "       [2.8405355e-02, 3.2216147e-01, 6.4943320e-01]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_6AJNiGhxhv",
    "outputId": "5a84fc36-e3cb-4425-a716-244bc1adaf4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_real_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2aq0056YF8W"
   },
   "outputs": [],
   "source": [
    "y_pred_eff=np.argmax(predictions_efficient, axis=1)\n",
    "y_real_eff= val_generator_EfficientNetB3.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "yLCwjv_SYR_A",
    "outputId": "63589361-e30c-4dcf-ad14-581da56f3908"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(y_real_eff, y_pred_eff, normalize='true');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4F_Fh3MKYgey",
    "outputId": "3010b166-f49e-47be-b3c1-79accc364840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7944    0.7409    0.7668       193\n",
      "           1     0.7405    0.7132    0.7266       136\n",
      "           2     0.5597    0.6466    0.6000       116\n",
      "\n",
      "    accuracy                         0.7079       445\n",
      "   macro avg     0.6982    0.7002    0.6978       445\n",
      "weighted avg     0.7168    0.7079    0.7110       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_real_eff,y_pred_eff, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6b5Z1Q6xj6Rg"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s39Q74SwYlJa",
    "outputId": "08a0b421-c542-4130-b2c8-af4e69b49471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(test_data_dir):\n",
    "  img=image.load_img(test_data_dir+'/'+i, target_size=(300,300))\n",
    "  X=image.img_to_array(img)\n",
    "  X=np.expand_dims(X,axis=0)\n",
    "  images=np.vstack([X])\n",
    "  val=EfficientNetB3_model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wPzioQxcqGE"
   },
   "outputs": [],
   "source": [
    "test_data_dir=ruta+\"/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2njfyygmpfOC",
    "outputId": "3d7ac086-8cb2-4c3a-fd71-7e29962e4947"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/Schneider competition/train_test_data/test'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whUex4OkpQkP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fISa5kHpCki"
   },
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('/content/drive/MyDrive/Schneider competition/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "_WsJAdUepmFS",
    "outputId": "2d2848b3-0118-4cba-c64e-c55d9a8d259b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f145a776-66dc-4e3a-ad23-97ec3b47340d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>year</th>\n",
       "      <th>example_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.761681</td>\n",
       "      <td>122.755954</td>\n",
       "      <td>2006</td>\n",
       "      <td>train_test_data/test/69.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.059785</td>\n",
       "      <td>113.053791</td>\n",
       "      <td>2007</td>\n",
       "      <td>train_test_data/test/469.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.006610</td>\n",
       "      <td>111.746316</td>\n",
       "      <td>2002</td>\n",
       "      <td>train_test_data/test/6.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.901765</td>\n",
       "      <td>114.042495</td>\n",
       "      <td>2016</td>\n",
       "      <td>train_test_data/test/351.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.911210</td>\n",
       "      <td>100.829633</td>\n",
       "      <td>2008</td>\n",
       "      <td>train_test_data/test/1001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>1.650899</td>\n",
       "      <td>101.314723</td>\n",
       "      <td>2011</td>\n",
       "      <td>train_test_data/test/968.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>-1.645649</td>\n",
       "      <td>102.612332</td>\n",
       "      <td>2010</td>\n",
       "      <td>train_test_data/test/54.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>-0.557796</td>\n",
       "      <td>114.561609</td>\n",
       "      <td>2016</td>\n",
       "      <td>train_test_data/test/494.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>-3.037549</td>\n",
       "      <td>113.872045</td>\n",
       "      <td>2009</td>\n",
       "      <td>train_test_data/test/287.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>-0.724728</td>\n",
       "      <td>102.432386</td>\n",
       "      <td>2009</td>\n",
       "      <td>train_test_data/test/603.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>635 rows × 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f145a776-66dc-4e3a-ad23-97ec3b47340d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f145a776-66dc-4e3a-ad23-97ec3b47340d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f145a776-66dc-4e3a-ad23-97ec3b47340d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     latitude   longitude  year                   example_path\n",
       "0    0.761681  122.755954  2006    train_test_data/test/69.png\n",
       "1   -8.059785  113.053791  2007   train_test_data/test/469.png\n",
       "2   -2.006610  111.746316  2002     train_test_data/test/6.png\n",
       "3    0.901765  114.042495  2016   train_test_data/test/351.png\n",
       "4    1.911210  100.829633  2008  train_test_data/test/1001.png\n",
       "..        ...         ...   ...                            ...\n",
       "630  1.650899  101.314723  2011   train_test_data/test/968.png\n",
       "631 -1.645649  102.612332  2010    train_test_data/test/54.png\n",
       "632 -0.557796  114.561609  2016   train_test_data/test/494.png\n",
       "633 -3.037549  113.872045  2009   train_test_data/test/287.png\n",
       "634 -0.724728  102.432386  2009   train_test_data/test/603.png\n",
       "\n",
       "[635 rows x 4 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g61JQ75VicRb",
    "outputId": "230bb912-b97f-4c80-8709-82cf73230c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py:991: UserWarning: Found 635 invalid image filename(s) in x_col=\"example_path\". These filename(s) will be ignored.\n",
      "  n_invalid, x_col))\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test_df,\n",
    "directory=\"/content/drive/MyDrive/Schneider competition/train_test_data/test/test/\",\n",
    "x_col=\"example_path\",\n",
    "y_col=None,\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gzsMHsiq1X-"
   },
   "outputs": [],
   "source": [
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iyiWgNhJuqOA"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image as image_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2zCepmOuKpA",
    "outputId": "57610022-4c2c-4912-d35d-071edfec4de4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "predicciones=[]\n",
    "for filename in test_df['example_path']:\n",
    "    # Load original via OpenCV, so we can draw on it and display it on our screen\n",
    "    original = cv2.imread(\"/content/drive/MyDrive/Schneider competition/\"+filename)\n",
    "\n",
    "    # Load image while resizing to 224x224 pixels, then convert to a NumPy array because load_img returns \n",
    "    # Pillow format\n",
    "    image = image_utils.load_img(\"/content/drive/MyDrive/Schneider competition/\"+filename, target_size=(224, 224))\n",
    "    image = image_utils.img_to_array(image)\n",
    "\n",
    "    \"\"\"\n",
    "    PRE-PROCESS\n",
    "    The image is now a NumPy array of shape (224, 224, 3). 224 pixels tall, 224 pixels wide, 3 channels = \n",
    "    Red, Green, Blue. We need to expand to (1, 3, 224, 224) because when classifying images using Deep\n",
    "    Learning and Convolutional Neural Networks, we often send several images (instead of one) through\n",
    "    the network in “batches” for efficiency. We also subtract the mean RGB pixel intensity from the\n",
    "    ImageNet dataset.\n",
    "    \"\"\"\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    predicciones.append(EfficientNetB3_model.predict(image))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJOyqcTMid9j"
   },
   "outputs": [],
   "source": [
    "predicciones=np.argmax(predicciones, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7fH1ipkwO-v",
    "outputId": "28d7b847-51b7-41b6-c0d6-c6e007149ab7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1jL2E5MwfZW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
